{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "maritime-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ambient-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from collections import namedtuple, defaultdict\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm, trange, tqdm_notebook\n",
    "import torch.nn as nn\n",
    "from radam import RAdam\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "available-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1233)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "assert device == 'cuda'\n",
    "\n",
    "BP = 0.0001\n",
    "\n",
    "mprms = dict(\n",
    "    epi_length=3000,\n",
    "    epi_test_length=10_000,\n",
    "    batch_size = 128,\n",
    "    hid_size= 512,\n",
    "    learning_rate = 1e-3,\n",
    "    epoches = 120,\n",
    "    alpha = 0.,\n",
    "    cost = 0.0*BP)\n",
    "\n",
    "\n",
    "CONFIG = mprms\n",
    "passport = dict(group = 'Base_1',tags = ['sa'],project_name = 'Zero_Test')\n",
    "\n",
    "\n",
    "TradingEpisode = namedtuple('TradingEpisode', ['prices', 'features'])\n",
    "EPS=1e-5 #Now desribed in functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "common-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eligible-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_multiplier = 1_000_000\n",
    "class MeanReversionSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, prices, epi_len):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.prices = prices\n",
    "        self.epi_len = epi_len\n",
    "        self.num_ticks = len(features)\n",
    "    def __getitem__(self, i):\n",
    "        features = torch.as_tensor(f_multiplier*self.features[i:i+self.epi_len] , dtype = torch.float32)\n",
    "        prices   = torch.as_tensor(self.prices  [i:i+self.epi_len] , dtype = torch.float32)\n",
    "        return TradingEpisode(prices = prices, features = features)\n",
    "    def __len__(self):\n",
    "        return self.num_ticks - self.epi_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acoustic-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m2m(model,  mkte):\n",
    "    actions = model(mkte.features)\n",
    "\n",
    "    new_positions = torch.matmul(torch.tensor([-1,0,1.0]).to(device),actions.permute(0,2,1) )\n",
    "\n",
    "    new_positions[:, -1] = torch.zeros_like(new_positions[:, -1])\n",
    "\n",
    "    d_positions = F.pad(new_positions[:,1:] - new_positions[:,:-1], (1,0))\n",
    "\n",
    "    d_cash = -d_positions* mkte.prices\n",
    "    #print(d_cash.shape)\n",
    "\n",
    "    cash = d_cash.sum(-1)\n",
    "    \n",
    "    m2m = torch.cumsum( d_cash , dim = -1) + new_positions* mkte.prices\n",
    "    #print(m2m.shape)\n",
    "    #print(torch.cummax(m2m, dim=-1))\n",
    "    m2m_drawdown = torch.cummax(m2m, dim=-1)[0]- m2m\n",
    "    m2m_drawdown = m2m_drawdown.mean(-1).mean()\n",
    "   # print(m2m_drawdown.shape)\n",
    "    \n",
    "    \n",
    "    m2m_final = cash - torch.mean(model.cost*torch.abs(d_cash)) #####!!!!!!!!! standart: without torch.mean(model.cost*torch.abs(d_cash))\n",
    "    return m2m_final, cash, new_positions, d_cash, m2m_drawdown, m2m\n",
    "\n",
    "\n",
    "def calc_episode(model, mkte, add_stat=False):\n",
    "    stats = defaultdict(list)\n",
    "    batch_size, n_timestamps, n_features = mkte.features.shape\n",
    "    zero_state = torch.zeros(batch_size, mprms['hid_size']).to(device)\n",
    "    initial_hid = (zero_state, zero_state)  # [h, c]\n",
    "    \n",
    "#     new_state, actions = model(mkte.features[:,0,:], initial_hid)\n",
    "    actions = model(mkte.features[:,0,:].to(device))\n",
    "\n",
    "    positions = torch.zeros(batch_size, requires_grad=True).to(device)\n",
    "    cash = torch.zeros_like(positions, requires_grad=True).to(device)\n",
    "    m2m  = torch.zeros_like(positions, requires_grad=True).to(device)\n",
    "    \n",
    "    for t in range(1, mprms['epi_length']-1):\n",
    "#         new_state, actions = model(mkte.features[:,t,:], new_state)\n",
    "        actions = model(mkte.features[:,t,:].to(device))\n",
    "        \n",
    "        if add_stat:\n",
    "            stats['t'] = t\n",
    "            stats['actions'].append(actions.cpu().detach().numpy())\n",
    "            \n",
    "        new_positions = torch.matmul(torch.tensor([-1,0,1.0]).to(device),actions.T)\n",
    "        if add_stat:\n",
    "            stats['positions'].append(new_positions.cpu().detach().numpy())\n",
    "        d_positions = new_positions - positions\n",
    "        d_cash = -d_positions* mkte.prices[:,t]\n",
    "        cash = cash + d_cash\n",
    "        new_m2m = cash + new_positions * mkte.prices[:,t]\n",
    "\n",
    "        if add_stat:\n",
    "            stats['m2m'].append(new_m2m.cpu().detach().numpy())\n",
    "        \n",
    "        positions = new_positions\n",
    "        m2m=new_m2m\n",
    "        \n",
    "    return m2m, cash, positions, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confidential-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms_artamonov\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-single",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "impressed-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, sharpe,tau,example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"train/loss\": loss,'train/sharpe' : sharpe}, step=example_ct)\n",
    "\n",
    "def train_val_log(sharpe, mean_R,example_ct, epoch):\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, 'val/sharpe' : sharpe,'val/mean_R' : mean_R}, step=example_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "literary-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrtfNNLin(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,num_features, hid_size, config, mkte,mkte_test, mkt_loader, tau=0.5):\n",
    "        super().__init__()\n",
    "        self.L1 = nn.Linear(num_features, hid_size)\n",
    "        self.L1A = nn.Tanh()\n",
    "        self.hid_to_actions = nn.Linear(hid_size, 3)\n",
    "        self.tau = tau\n",
    "        self.hard = False\n",
    "        \n",
    "        self.mkte = mkte\n",
    "        self.mkt_loader = mkt_loader\n",
    "        self.mkte_test = mkte_test\n",
    "        \n",
    "        self.n_iter = config['epoches']\n",
    "        self.alpha = config['alpha']\n",
    "        self.lr = config['learning_rate']\n",
    "        self.cost = config['cost']\n",
    "\n",
    "    def forward(self, inp_features):\n",
    "        inp_features = inp_features.to(device)\n",
    "        l2 = self.L1(inp_features) \n",
    "        #print(l2.shape)        \n",
    "        l2a = self.L1A(l2)\n",
    "        action_seq = self.hid_to_actions( l2a )\n",
    "        final_actions = torch.nn.functional.gumbel_softmax(action_seq, hard=self.hard, tau=self.tau)\n",
    "        return final_actions\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        mkte = batch\n",
    "        mkte = TradingEpisode(*map(lambda x: x.to(device), mkte))\n",
    "        m2m_final, cash, new_positions, d_cash, m2m_drawdown, M2M = calc_m2m(self, mkte)\n",
    "        mean_ret = m2m_final.mean()\n",
    "               # print('M2M.shape: {} \\nmean_ret: {}'.format(m2m.shape,mean_ret))\n",
    "        sharpe = mean_ret / (m2m_final.std() + EPS)\n",
    "                #print(m2m.shape)\n",
    "                #print(sharpe.shape)\n",
    "                #loss = -sharpe - alpha*m2m_drawdown     Very Stupid))\n",
    "        #print('len(d_cash) = ',d_cash.shape)\n",
    "        loss = -sharpe + self.alpha*m2m_drawdown +torch.mean(self.cost*torch.abs(d_cash)) #self.cost*torch.abs(d_cash[-1]) #torch.sum(self.cost*torch.abs(d_cash))\n",
    "            \n",
    "        # Logging to TensorBoard by default\n",
    "        self.logger.experiment.log({'train_loss': loss.item(),'train_sharpe':sharpe.item()})\n",
    "        \n",
    "        #m2m_final, cash, new_positions, d_cash, m2m_drawdown, m2m\n",
    "        with torch.no_grad():\n",
    "            m2m, cash, positions,_,_,_ = calc_m2m(self, self.mkte_test)\n",
    "        R = np.stack(m2m.cpu().detach().numpy()).reshape(-1)\n",
    "        mean_R = np.mean(R)\n",
    "        sharpe_val = mean_R / (np.std(R) + EPS)\n",
    "        \n",
    "        self.logger.experiment.log({'val/mean_R': mean_R,'val/sharpe':sharpe_val})\n",
    "            \n",
    "                \n",
    "\n",
    "        #self.logger.experiment.log()\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = RAdam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "devoted-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(config, comp):\n",
    "    # Make the data\n",
    "    \n",
    "    \n",
    "    features = pd.DataFrame(dict(px = comp)).assign(\n",
    "    dpx1 = lambda x: x.px - x.px.ewm(64).mean(),\n",
    "    dpx2 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "    dpx3 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "    dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean())\n",
    "\n",
    "    \n",
    "    split_idx = int(comp.shape[0]*0.7)\n",
    "    train_comp = comp[:split_idx]\n",
    "    test_comp = comp[split_idx:]\n",
    "    \n",
    "    train_features = pd.DataFrame(dict(px = train_comp)).assign(\n",
    "    dpx1 = lambda x: x.px - x.px.ewm(64).mean(),\n",
    "    dpx2 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "    dpx3 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "    dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean())\n",
    "\n",
    "    test_features = features[split_idx:]\n",
    "    \n",
    "    \n",
    "    \n",
    "   # train, test = get_data(train=True), get_data(train=False)\n",
    "    #train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    #test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "    \n",
    "    f_train_values = train_features.filter(like = 'dp').values\n",
    "    f_test_values = test_features.filter(like = 'dp').values\n",
    "    \n",
    "    dataset = MeanReversionSet(f_train_values, train_features['px'].values, epi_len = mprms['epi_length'])\n",
    "    mkt_loader = torch.utils.data.DataLoader(dataset, batch_size=mprms['batch_size'], shuffle=True, num_workers=4)\n",
    "    n_features = f_train_values.shape[1]\n",
    "\n",
    "    testset = MeanReversionSet(f_test_values, test_features['px'].values, epi_len = mprms['epi_test_length'])\n",
    "    mkt_tst_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=1)\n",
    "    n_test_features = f_test_values.shape[1]\n",
    "    \n",
    "\n",
    "\n",
    "    # Make the model\n",
    "\n",
    "   \n",
    "\n",
    "    mkte = next(iter(mkt_loader))\n",
    "    mkte = TradingEpisode(*map(lambda x: x.to(device), mkte))\n",
    "    zero_state = torch.zeros(config['batch_size'], config['hid_size']).to(device)\n",
    "    initial_hid = (zero_state, zero_state)  # [h, c]\n",
    "    # res = model(mkte.features[:,0,:], initial_hid)\n",
    "    #res = model(mkte.features[:,0,:])\n",
    "    \n",
    "    mkte_test = next(iter(mkt_tst_loader))\n",
    "    mkte_test = TradingEpisode(*map(lambda x: x.to(device), mkte_test))\n",
    "    zero_state_tst = torch.zeros(1, mprms['hid_size']).to(device)\n",
    "    initial_hid_tst = (zero_state_tst, zero_state_tst)  # [h, c]  \n",
    "    \n",
    "    model = PrtfNNLin(n_features,mprms['hid_size'],config, mkte,mkte_test, mkt_loader).to(device)\n",
    "    \n",
    "    return model, dataset, testset, mkte, mkte_test, mkt_loader, mkt_tst_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lesser-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comp.pck', 'rb') as f:\n",
    "    comp = pickle.load(f)\n",
    "comp = comp[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "restricted-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, mkte_test):\n",
    "    with torch.no_grad():\n",
    "        m2m, cash, positions, stat = calc_episode(model, mkte_test, True)\n",
    "    RW = m2m.mean() / (m2m.std() + EPS)\n",
    "    plt.plot( np.stack(stat['m2m']).T[0,:])\n",
    "    \n",
    "def model_pipeline(hyperparameters, comp):\n",
    "    # tell wandb to get started\n",
    "      with wandb.init(project=passport['project_name'], group=passport['group'], tags=passport['tags'], config=hyperparameters, save_code=False):    \n",
    "#    with wandb.init(config=hyperparameters):\n",
    "\n",
    "    # access all HPs through wandb.config, so logging matches execution!\n",
    "            config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "            model, dataset, testset, mkte, mkte_test, mkt_loader, mkt_tst_loader = setup_experiment(CONFIG, comp)\n",
    "            print(model)\n",
    "            trainer = pl.Trainer(gpus=1,logger=wandb_logger,max_epochs=hyperparameters['epoches'])\n",
    "            with tqdm(mkt_loader) as mkt_loader:\n",
    "                trainer.fit(model,mkt_loader)\n",
    "      # and use them to train the model\n",
    "\n",
    "\n",
    "      # and test its final performance\n",
    "           # test(model, mkte_test)\n",
    "\n",
    "      return model,mkte_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "molecular-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = []\n",
    "MKTE_TESTS = []\n",
    "\n",
    "ALPHAS = [0.05,0.1,0.15]\n",
    "COSTS = [0.1,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-veteran",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rich-valley-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/s_artamonov/Zero_Test\" target=\"_blank\">https://wandb.ai/s_artamonov/Zero_Test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/s_artamonov/Zero_Test/runs/15vp9ki2\" target=\"_blank\">https://wandb.ai/s_artamonov/Zero_Test/runs/15vp9ki2</a><br/>\n",
       "                Run data is saved locally in <code>/home/Serega200010/T-Digital_Project/wandb/run-20210308_210509-15vp9ki2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrtfNNLin(\n",
      "  (L1): Linear(in_features=4, out_features=512, bias=True)\n",
      "  (L1A): Tanh()\n",
      "  (hid_to_actions): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5fa511f42b46dc922412b2810cf9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=360.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type   | Params\n",
      "------------------------------------------\n",
      "0 | L1             | Linear | 2.6 K \n",
      "1 | L1A            | Tanh   | 0     \n",
      "2 | hid_to_actions | Linear | 1.5 K \n",
      "------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fbd810dbba4aecb6a08300df3c76e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Serega200010/T-Digital_Project/radam.py:58: UserWarning: This overload of addcmul_ is deprecated:\n",
      "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in ALPHAS:\n",
    "    for cost in COSTS:\n",
    "        mprms = dict(\n",
    "                        epi_length=3000,\n",
    "                        epi_test_length=10_000,\n",
    "                        batch_size = 128,\n",
    "                        hid_size= 512,\n",
    "                        learning_rate = 1e-3,\n",
    "                        epoches = 120,\n",
    "                        alpha = alpha,\n",
    "                        cost = cost*BP)\n",
    "\n",
    "\n",
    "        CONF = mprms\n",
    "        model,mkte_test = model_pipeline(CONF,comp)\n",
    "        \n",
    "        MODELS.append(model)\n",
    "        MKTE_TESTS.append(mkte_test)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alpha-weekend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: <ipython-input-12-b702c3e9203e> 9 model_pipeline\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8e20e882fe4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmkte_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b702c3e9203e>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters, comp)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# tell wandb to get started\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'project_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#    with wandb.init(config=hyperparameters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# initiate run (stats and metadata probing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mrun_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_obj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_obj_offline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_run_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_run_start\u001b[0;34m(self, run_pb)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mrun_start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     ) -> Optional[pb.Result]:\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_Future\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mis_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_set\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model.to(device),mkte_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comfortable-installation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "grave-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precise-stanford",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mkt_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8839c6cc9877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmkt_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmkt_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmkt_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mkt_loader' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fitted-personal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrtfNNLin(\n",
       "  (L1): Linear(in_features=4, out_features=512, bias=True)\n",
       "  (L1A): Tanh()\n",
       "  (hid_to_actions): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-ideal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concrete-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from collections import namedtuple, defaultdict\n",
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm, trange, tqdm_notebook\n",
    "import torch.nn as nn\n",
    "from radam import RAdam\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "#SummaryWriter encapsulates everything\n",
    "exp_name = 'exp-2-LNN_V1'\n",
    "writer = SummaryWriter(f\"pnet/{exp_name}\")\n",
    "\n",
    "torch.manual_seed(1233)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "#assert device =='cuda'\n",
    "\n",
    "\n",
    "TradingEpisode = namedtuple('TradingEpisode', ['prices', 'features'])\n",
    "EPS=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "burning-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "mprms = dict(\n",
    "    epi_length=3000,\n",
    "    epi_test_length=10_000,\n",
    "    batch_size = 128,\n",
    "    hid_size= 512,\n",
    "    learning_rate = 1e-3,\n",
    "    epoches = 5,\n",
    "    alpha = 0.05)\n",
    "\n",
    "\n",
    "CONFIG = mprms\n",
    "passport = dict(group = 'Base_1',tags = ['sa'],project_name = 'Zero_Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "careful-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_multiplier = 1_000_000\n",
    "class MeanReversionSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, prices, epi_len):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.prices = prices\n",
    "        self.epi_len = epi_len\n",
    "        self.num_ticks = len(features)\n",
    "    def __getitem__(self, i):\n",
    "        features = torch.as_tensor(f_multiplier*self.features[i:i+self.epi_len] , dtype = torch.float32)\n",
    "        prices   = torch.as_tensor(self.prices  [i:i+self.epi_len] , dtype = torch.float32)\n",
    "        return TradingEpisode(prices = prices, features = features)\n",
    "    def __len__(self):\n",
    "        return self.num_ticks - self.epi_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naval-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_NN:\n",
    "    def __init__(self):\n",
    "        self.MLAlgorithm = None\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.mprms = dict(\n",
    "            epi_length=3000,\n",
    "            epi_test_length=10_000,\n",
    "            batch_size = 128,\n",
    "            hid_size= 512,\n",
    "            learning_rate = 1e-3)\n",
    "        #self.test_features = None\n",
    "        #self.train_features = None\n",
    "\n",
    "    def setMLAlgorithm(self, ML): # CAN BE CHANGED, BUT WE DON'T ADVISE TO DO THAT\n",
    "        self.MLAlgorithm = ML\n",
    "\n",
    "    def dataPreparation(self, DP,MRPRMS = None, start_point = 0.7): \n",
    "        device = self.device\n",
    "        mprms = MRPRMS\n",
    "        if mprms == None:\n",
    "            mprms = self.mprms\n",
    "        \n",
    "        features = pd.DataFrame(dict(px = DP)).assign(\n",
    "        dpx1 = lambda x: x.px - x.px.ewm(64).mean(),\n",
    "        dpx2 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "        dpx3 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "        dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean())\n",
    "       # split_idx = int(features.shape[0]*0.7)\n",
    "       # self.train_features = features[:split_idx]\n",
    "       # self.test_features = features[split_idx:]\n",
    "        \n",
    "        split_idx = int(features.shape[0]*start_point)\n",
    "        f_features = features[split_idx:].filter(like = 'dp').values\n",
    "        \n",
    "        dataset = MeanReversionSet(f_features, features['px'].values, epi_len = mprms['epi_length'])\n",
    "        mkt_loader = torch.utils.data.DataLoader(dataset, batch_size=mprms['batch_size'], shuffle=True, num_workers=4)\n",
    "        n_features = f_features.shape[1]\n",
    "        \n",
    "        mkte = next(iter(mkt_loader))\n",
    "        mkte = TradingEpisode(*map(lambda x: x.to(device), mkte))\n",
    "        \n",
    "        \n",
    "\n",
    "        return mkte.features\n",
    "    \n",
    "    \n",
    "    def getPosition(self, DP):\n",
    "        X = self.dataPreparation(DP)\n",
    "        Y = self.MLAlgorithm(X[:,0,:])\n",
    "        for t in range(1,X.shape[1]):\n",
    "            act = self.MLAlgorithm(X[:,t,:])\n",
    "            Y = torch.cat((Y,act),0)\n",
    "        return Y\n",
    "\n",
    "    def serialize(self, fileName): # do NOT ever change or remove it!!!\n",
    "        type_data = pickle.dumps(Strategy)# <= DEFINE YOUR OWN TYPE!!!!!!!\n",
    "        self_data = pickle.dumps(self)\n",
    "        with open(fileName, 'wb') as f:\n",
    "            pickle.dump((type_data, self_data), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "detailed-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('from_mansur.pck', 'rb') as f:\n",
    "    comp = pickle.load(f)\n",
    "comp = comp[:70000]\n",
    "split_idx = int(comp.shape[0]*0.7)\n",
    "train_comp = comp[:split_idx]\n",
    "test_comp = comp[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acceptable-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrtfNNLin(nn.Module):\n",
    "    \"\"\" A neural network that generates signals \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, hid_size=mprms['hid_size'], tau=0.5):\n",
    "        super().__init__()\n",
    "        self.L1 = nn.Linear(num_features, hid_size)\n",
    "        self.L1A = nn.Tanh()\n",
    "        self.hid_to_actions = nn.Linear(hid_size, 3)\n",
    "        self.tau = tau\n",
    "        self.hard = False\n",
    "    def forward(self, inp_features):\n",
    "        l2 = self.L1(inp_features) \n",
    "        #print(l2.shape)        \n",
    "        l2a = self.L1A(l2)\n",
    "        action_seq = self.hid_to_actions( l2a )\n",
    "        final_actions = torch.nn.functional.gumbel_softmax(action_seq, hard=self.hard, tau=self.tau)\n",
    "        return final_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "floating-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(config, comp):\n",
    "    # Make the data\n",
    "    \n",
    "    \n",
    "    features = pd.DataFrame(dict(px = comp)).assign(\n",
    "    dpx1 = lambda x: x.px - x.px.ewm(64).mean(),\n",
    "    dpx2 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "    dpx3 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "    dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean())\n",
    "\n",
    "    \n",
    "    split_idx = int(comp.shape[0]*0.7)\n",
    "    train_comp = comp[:split_idx]\n",
    "    test_comp = comp[split_idx:]\n",
    "    \n",
    "    train_features = pd.DataFrame(dict(px = train_comp)).assign(\n",
    "    dpx1 = lambda x: x.px - x.px.ewm(64).mean(),\n",
    "    dpx2 = lambda x: x.px.ewm(64).mean() - x.px.ewm(128).mean(),\n",
    "    dpx3 = lambda x: x.px.ewm(128).mean() - x.px.ewm(256).mean(),\n",
    "    dpx4 = lambda x: x.px.ewm(256).mean() - x.px.ewm(512).mean())\n",
    "\n",
    "    test_features = features[split_idx:]\n",
    "    \n",
    "    \n",
    "    \n",
    "   # train, test = get_data(train=True), get_data(train=False)\n",
    "    #train_loader = make_loader(train, batch_size=config.batch_size)\n",
    "    #test_loader = make_loader(test, batch_size=config.batch_size)\n",
    "    \n",
    "    f_train_values = train_features.filter(like = 'dp').values\n",
    "    f_test_values = test_features.filter(like = 'dp').values\n",
    "    \n",
    "    dataset = MeanReversionSet(f_train_values, train_features['px'].values, epi_len = mprms['epi_length'])\n",
    "    mkt_loader = torch.utils.data.DataLoader(dataset, batch_size=mprms['batch_size'], shuffle=True, num_workers=4)\n",
    "    n_features = f_train_values.shape[1]\n",
    "\n",
    "    testset = MeanReversionSet(f_test_values, test_features['px'].values, epi_len = mprms['epi_test_length'])\n",
    "    mkt_tst_loader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=1)\n",
    "    n_test_features = f_test_values.shape[1]\n",
    "    \n",
    "\n",
    "\n",
    "    # Make the model\n",
    "    model = PrtfNNLin(n_features).to(device)\n",
    "    opt = RAdam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    mkte = next(iter(mkt_loader))\n",
    "    mkte = TradingEpisode(*map(lambda x: x.to(device), mkte))\n",
    "    zero_state = torch.zeros(config['batch_size'], config['hid_size']).to(device)\n",
    "    initial_hid = (zero_state, zero_state)  # [h, c]\n",
    "    # res = model(mkte.features[:,0,:], initial_hid)\n",
    "    #res = model(mkte.features[:,0,:])\n",
    "    \n",
    "    mkte_test = next(iter(mkt_tst_loader))\n",
    "    mkte_test = TradingEpisode(*map(lambda x: x.to(device), mkte_test))\n",
    "    zero_state_tst = torch.zeros(1, mprms['hid_size']).to(device)\n",
    "    initial_hid_tst = (zero_state_tst, zero_state_tst)  # [h, c]    \n",
    "\n",
    "    \n",
    "    return model, dataset, testset,  opt, mkte, mkte_test, mkt_loader, mkt_tst_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "descending-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, dataset, testset,  opt, mkte, mkte_test, mkt_loader, mkt_tst_loader = setup_experiment(CONFIG,comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handmade-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms_artamonov\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "threaded-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_log(loss, sharpe,tau,example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, \"train/loss\": loss,'train/sharpe' : sharpe}, step=example_ct)\n",
    "    #print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")\n",
    "\n",
    "def train_val_log(sharpe, mean_R,example_ct, epoch):\n",
    "    # where the magic happens\n",
    "    wandb.log({\"epoch\": epoch, 'val/sharpe' : sharpe,'val/mean_R' : mean_R}, step=example_ct)\n",
    "   # print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "intended-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m2m(model,  mkte):\n",
    "    actions = model(mkte.features)\n",
    "\n",
    "    new_positions = torch.matmul(torch.tensor([-1,0,1.0]).to(device),actions.permute(0,2,1) )\n",
    "\n",
    "    new_positions[:, -1] = torch.zeros_like(new_positions[:, -1])\n",
    "\n",
    "    d_positions = F.pad(new_positions[:,1:] - new_positions[:,:-1], (1,0))\n",
    "\n",
    "    d_cash = -d_positions* mkte.prices\n",
    "    #print(d_cash.shape)\n",
    "\n",
    "    cash = d_cash.sum(-1)\n",
    "    \n",
    "    m2m = torch.cumsum( d_cash , dim = -1) + new_positions* mkte.prices\n",
    "    #print(m2m.shape)\n",
    "    #print(torch.cummax(m2m, dim=-1))\n",
    "    m2m_drawdown = torch.cummax(m2m, dim=-1)[0]- m2m\n",
    "    m2m_drawdown = m2m_drawdown.mean(-1).mean()\n",
    "   # print(m2m_drawdown.shape)\n",
    "    \n",
    "    \n",
    "    m2m_final = cash\n",
    "    return m2m_final, cash, new_positions, d_cash, m2m_drawdown, m2m\n",
    "\n",
    "\n",
    "def calc_episode(model, mkte, add_stat=False):\n",
    "    stats = defaultdict(list)\n",
    "    batch_size, n_timestamps, n_features = mkte.features.shape\n",
    "    zero_state = torch.zeros(batch_size, mprms['hid_size']).to(device)\n",
    "    initial_hid = (zero_state, zero_state)  # [h, c]\n",
    "    \n",
    "#     new_state, actions = model(mkte.features[:,0,:], initial_hid)\n",
    "    actions = model(mkte.features[:,0,:])\n",
    "\n",
    "    positions = torch.zeros(batch_size, requires_grad=True).to(device)\n",
    "    cash = torch.zeros_like(positions, requires_grad=True).to(device)\n",
    "    m2m  = torch.zeros_like(positions, requires_grad=True).to(device)\n",
    "    \n",
    "    for t in range(1, mprms['epi_length']-1):\n",
    "#         new_state, actions = model(mkte.features[:,t,:], new_state)\n",
    "        actions = model(mkte.features[:,t,:])\n",
    "        \n",
    "        if add_stat:\n",
    "            stats['t'] = t\n",
    "            stats['actions'].append(actions.cpu().detach().numpy())\n",
    "            \n",
    "        new_positions = torch.matmul(torch.tensor([-1,0,1.0]).to(device),actions.T)\n",
    "        if add_stat:\n",
    "            stats['positions'].append(new_positions.cpu().detach().numpy())\n",
    "        d_positions = new_positions - positions\n",
    "        d_cash = -d_positions* mkte.prices[:,t]\n",
    "        cash = cash + d_cash\n",
    "        new_m2m = cash + new_positions * mkte.prices[:,t]\n",
    "\n",
    "        if add_stat:\n",
    "            stats['m2m'].append(new_m2m.cpu().detach().numpy())\n",
    "        \n",
    "        positions = new_positions\n",
    "        m2m=new_m2m\n",
    "        \n",
    "    return m2m, cash, positions, stats\n",
    "\n",
    "def train(model,mkt_loader,config,opt = opt):\n",
    "    sharpe_max = 0\n",
    "    t = 0\n",
    "    l_hist = list()\n",
    "    n_iter = config['epoches']\n",
    "    alpha = config['alpha']\n",
    "    while t < n_iter:\n",
    "        with tqdm(mkt_loader) as mkt_loader:\n",
    "            i = -1\n",
    "            for mkte in mkt_loader:\n",
    "                i+=1\n",
    "                mkte = TradingEpisode(*map(lambda x: x.to(device), mkte))\n",
    "            \n",
    "                m2m_final, cash, new_positions, d_cash, m2m_drawdown, M2M = calc_m2m(model, mkte)\n",
    "                mean_ret = m2m_final.mean()\n",
    "               # print('M2M.shape: {} \\nmean_ret: {}'.format(m2m.shape,mean_ret))\n",
    "                sharpe = mean_ret / (m2m_final.std() + EPS)\n",
    "                #print(m2m.shape)\n",
    "                #print(sharpe.shape)\n",
    "                #loss = -sharpe - alpha*m2m_drawdown     Very Stupid))\n",
    "                loss = -sharpe + alpha*m2m_drawdown\n",
    "               #print(loss.shape)\n",
    "                loss.backward()\n",
    "\n",
    "                opt.step()\n",
    "\n",
    "                opt.zero_grad()\n",
    "                \n",
    "                train_log(loss.item(),sharpe.item(),model.tau,i,t)\n",
    "                \n",
    "               # writer.add_scalar('train/loss', loss.item(), t)\n",
    "                #writer.add_scalar('train/sharpe', sharpe.item(), t)\n",
    "                #writer.add_scalar('train/tau', model.tau, t)\n",
    "            \n",
    "                l_hist.append(loss.item())\n",
    "                if t%20==0:\n",
    "                    with torch.no_grad():\n",
    "                        m2m_final, cash, positions, d_cash, m2m_drawdown, M2M = calc_m2m(model, mkte_test)\n",
    "                    R = np.stack(m2m_final.cpu().detach().numpy()).reshape(-1)\n",
    "                    mean_R = np.mean(R)\n",
    "                    sharpe = mean_R / (np.std(R) + EPS)\n",
    "                \n",
    "                    if sharpe > sharpe_max:\n",
    "                    \n",
    "                        torch.save(model, f\"pnet/{exp_name}/model_{t}.chk\")\n",
    "                        sharpe_max = sharpe\n",
    "                    train_val_log(sharpe, mean_R,i, t)\n",
    "                    #writer.add_scalar('test/sharpe', sharpe, t)\n",
    "                    #writer.add_scalar('test/mean_R', mean_R, t)\n",
    "                \n",
    "                t+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "silent-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, mkte_test):\n",
    "    with torch.no_grad():\n",
    "        m2m, cash, positions, stat = calc_episode(model, mkte_test, True)\n",
    "    RW = m2m.mean() / (m2m.std() + EPS)\n",
    "    plt.plot( np.stack(stat['m2m']).T[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "secret-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters, comp):\n",
    "    # tell wandb to get started\n",
    "      with wandb.init(project=passport['project_name'], group=passport['group'], tags=passport['tags'], config=hyperparameters, save_code=False):    \n",
    "#    with wandb.init(config=hyperparameters):\n",
    "\n",
    "    # access all HPs through wandb.config, so logging matches execution!\n",
    "          config = wandb.config\n",
    "\n",
    "      # make the model, data, and optimization problem\n",
    "          model, dataset, testset,  opt, mkte, mkte_test, mkt_loader, mkt_tst_loader = make(config,comp)\n",
    "          print(model)\n",
    "\n",
    "      # and use them to train the model\n",
    "          train(model,mkt_loader,config,opt)\n",
    "\n",
    "      # and test its final performance\n",
    "          test(model, mkte_test)\n",
    "\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "third-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb version 0.10.18.dev1 has been retired!  Please upgrade.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.18.dev1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">earnest-sponge-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/s_artamonov/Zero_Test\" target=\"_blank\">https://wandb.ai/s_artamonov/Zero_Test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/s_artamonov/Zero_Test/runs/3rdgeeq2\" target=\"_blank\">https://wandb.ai/s_artamonov/Zero_Test/runs/3rdgeeq2</a><br/>\n",
       "                Run data is saved locally in <code>/home/Serega200010/T-Digital_Project/wandb/run-20210304_130155-3rdgeeq2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrtfNNLin(\n",
      "  (L1): Linear(in_features=4, out_features=512, bias=True)\n",
      "  (L1A): Tanh()\n",
      "  (hid_to_actions): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6de888c5fff496ab7a6099c1975008c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=360.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 639324<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/Serega200010/T-Digital_Project/wandb/run-20210304_130155-3rdgeeq2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/Serega200010/T-Digital_Project/wandb/run-20210304_130155-3rdgeeq2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>359</td></tr><tr><td>train/loss</td><td>-0.26948</td></tr><tr><td>train/sharpe</td><td>0.54275</td></tr><tr><td>val/sharpe</td><td>-3464843.75</td></tr><tr><td>val/mean_R</td><td>-34.64844</td></tr><tr><td>_runtime</td><td>251</td></tr><tr><td>_timestamp</td><td>1614863166</td></tr><tr><td>_step</td><td>359</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/loss</td><td>█▆█▇▆▆▆▅▄▅▄▃▄▄▄▃▃▃▂▁▃▃▂▂▂▂▃▃▁▁▃▃▂▂▂▂▂▁▁▄</td></tr><tr><td>train/sharpe</td><td>▂▃▁▂▃▂▂▃▅▄▅▆▅▅▅▅▆▆▇▇▆▆▇▇▇▇▆▆██▆▆▇▇▇▇▇██▅</td></tr><tr><td>val/sharpe</td><td>█▂█▇▁▇█▄▄█▄▃▄▄▅▅▄▄</td></tr><tr><td>val/mean_R</td><td>█▂█▇▁▇█▄▄█▄▃▄▄▅▅▄▄</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">earnest-sponge-2</strong>: <a href=\"https://wandb.ai/s_artamonov/Zero_Test/runs/3rdgeeq2\" target=\"_blank\">https://wandb.ai/s_artamonov/Zero_Test/runs/3rdgeeq2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m wandb version 0.10.18.dev1 has been retired!  Please upgrade.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(CONFIG, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-contact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
